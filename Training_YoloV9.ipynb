{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sajivhar4118/Rat-NOR/blob/main/Training_YoloV9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQjdUKvQigN2"
      },
      "source": [
        "# Train and Run YOLOv9 on a Custom Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m09A8n4djDwY"
      },
      "source": [
        "## Before you start\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5hX88yficL7",
        "outputId": "f1381faa-353d-4088-fd5c-1b710aef537e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 14 16:15:21 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTprsNjHja4l"
      },
      "source": [
        "**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rowKDIT-jJ9k",
        "outputId": "be730c31-c0cc-473f-f71b-ca4a8742e983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWRGGT7Zjjbq"
      },
      "source": [
        "## Clone and Install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WyY-fboBLZB"
      },
      "source": [
        "**NOTE:** YOLOv9 is very new. At the moment, we recommend using a fork of the main repository. The `detect.py` script contains a bug that prevents inference. This bug is patched in the fork."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pixgo4qnjdoU",
        "outputId": "9190008f-760d-49db-8643-5ac0a56bde35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov9'...\n",
            "remote: Enumerating objects: 325, done.\u001b[K\n",
            "remote: Total 325 (delta 0), reused 0 (delta 0), pack-reused 325 (from 1)\u001b[K\n",
            "Receiving objects: 100% (325/325), 2.25 MiB | 4.84 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n",
            "/content/yolov9\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SkalskiP/yolov9.git\n",
        "%cd yolov9\n",
        "!pip install -r requirements.txt -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcx7KoNzqpgz"
      },
      "source": [
        "**NOTE:** Let's install the [`roboflow`](https://pypi.org/project/roboflow) package, which we will use to download our dataset from [Roboflow Universe](https://universe.roboflow.com/)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2QnrrXO-FXoP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPGqlohQqgAO",
        "outputId": "21a5cc18-5b5c-4445-ea89-25fa03f8f6dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/80.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.4/80.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8oLIkX2l2P0"
      },
      "source": [
        "## Download model weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FieRuZnB4wH"
      },
      "source": [
        "**NOTE:** In the YOLOv9 paper, versions `yolov9-s` and `yolov9-m` are also mentioned, but the weights for these models are not yet available in the YOLOv9 [repository](https://github.com/WongKinYiu/yolov9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h7j3aUE7l1Je"
      },
      "outputs": [],
      "source": [
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-e.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au6np1JS8eRB",
        "outputId": "cfc21437-e4a4-4dfc-b672-9238bd766d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 402444\n",
            "drwxr-xr-x 2 root root      4096 Oct 14 16:15 .\n",
            "drwxr-xr-x 1 root root      4096 Oct 14 16:15 ..\n",
            "-rw-r--r-- 1 root root  51508261 Feb 18  2024 gelan-c.pt\n",
            "-rw-r--r-- 1 root root 117203713 Feb 18  2024 gelan-e.pt\n",
            "-rw-r--r-- 1 root root 103153312 Feb 18  2024 yolov9-c.pt\n",
            "-rw-r--r-- 1 root root 140217688 Feb 18  2024 yolov9-e.pt\n"
          ]
        }
      ],
      "source": [
        "!ls -la {HOME}/weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7fZKrxsq_td"
      },
      "source": [
        "## Authenticate and Download the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5yx2GkI2P7Q"
      },
      "source": [
        "**NOTE:** The dataset must be saved inside the `{HOME}/yolov9` directory, otherwise, the training will not succeed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyLpftfU2Q1U",
        "outputId": "0fb4bfe2-721e-4beb-cfc8-c267f2bdb274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov9\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}/yolov9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eosmGt89vMO1"
      },
      "source": [
        "**NOTE:** In this tutorial, I will use the [football-players-detection](https://universe.roboflow.com/roboflow-jvuqo/football-players-detection-3zvbc) dataset. Feel free to replace it with your dataset in YOLO format or use another dataset available on [Roboflow Universe](https://universe.roboflow.com). Additionally, if you plan to deploy your model to Roboflow after training, make sure you are the owner of the dataset and that no model is associated with the version of the dataset you are going to training on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J3s_2_7p_gn",
        "outputId": "e0db31ae-0ed4-4cdb-ead9-253522beb5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.47)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.54.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in RAT_NOR-6 to yolov9:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1984/1984 [00:00<00:00, 6431.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to RAT_NOR-6 in yolov9:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [00:00<00:00, 6064.41it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"J7z40ETZmhYtsMn31GeD\")\n",
        "project = rf.workspace(\"ratnor\").project(\"rat_nor\")\n",
        "version = project.version(6)\n",
        "dataset = version.download(\"yolov9\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTbGpF2IsZ24"
      },
      "source": [
        "## Train Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N68Bdf4FsMYW",
        "outputId": "f1ca746c-ffec-4204-d1ac-b028d81a01c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov9\n",
            "2024-10-01 00:02:06.001771: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-01 00:02:06.021962: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-01 00:02:06.028007: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-01 00:02:06.042408: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-01 00:02:07.288587: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/weights/gelan-c.pt, cfg=/content/yolov9/models/detect/gelan-c.yaml, data=/content/yolov9/RAT_NOR-6/data.yaml, hyp=hyp.scratch-high.yaml, epochs=100, batch_size=16, imgsz=480, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "YOLOv5 ðŸš€ 1e33dbb Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, dfl=1.5, obj_pw=1.0, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO ðŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 22.2MB/s]\n",
            "/content/yolov9/train.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(weights, map_location='cpu')  # load checkpoint to CPU to avoid CUDA memory leak\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
            "  3                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            "  4                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
            "  5                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  6                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  7                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  8                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  9                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n",
            " 10                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 11           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 12                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n",
            " 16                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            " 17          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 18                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n",
            " 19                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            " 20           [-1, 9]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 22      [15, 18, 21]  1   5492182  models.yolo.DDetect                     [2, [256, 512, 512]]          \n",
            "gelan-c summary: 621 layers, 25438614 parameters, 25438598 gradients, 103.2 GFLOPs\n",
            "\n",
            "Transferred 931/937 items from /content/weights/gelan-c.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov9/RAT_NOR-6/train/labels... 68 images, 0 backgrounds, 0 corrupt: 100% 68/68 [00:00<00:00, 944.77it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov9/RAT_NOR-6/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov9/RAT_NOR-6/valid/labels... 19 images, 0 backgrounds, 0 corrupt: 100% 19/19 [00:00<00:00, 699.37it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov9/RAT_NOR-6/valid/labels.cache\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "/content/yolov9/train.py:244: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
            "Image sizes 480 train, 480 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/yolov9/train.py:302: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/99      6.31G      2.163      7.607      1.165         75        480:   0% 0/5 [00:04<?, ?it/s]Exception in thread Thread-11 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 300, in plot_images\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "       0/99      6.31G      2.163      7.607      1.165         75        480:  20% 1/5 [00:11<00:47, 11.92s/it]/content/yolov9/train.py:302: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/99       6.4G      2.209      7.426       1.14         67        480:  40% 2/5 [00:12<00:15,  5.33s/it]Exception in thread Thread-12 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 300, in plot_images\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "       0/99       6.4G      2.236      7.387      1.159         60        480:  60% 3/5 [00:13<00:06,  3.11s/it]Exception in thread Thread-13 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 300, in plot_images\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/content/yolov9/utils/plots.py\", line 86, in box_label\n",
            "    w, h = self.font.getsize(label)  # text width, height\n",
            "AttributeError: 'FreeTypeFont' object has no attribute 'getsize'\n",
            "       0/99       6.4G      2.326      7.714      1.223          8        480: 100% 5/5 [00:13<00:00,  2.79s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.78s/it]\n",
            "                   all         19         38   0.000485      0.105    0.00423   0.000444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/99      6.42G      2.455      8.229      1.256         21        480: 100% 5/5 [00:02<00:00,  1.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.36it/s]\n",
            "                   all         19         38   0.000485      0.105    0.00593    0.00119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/99      6.42G      2.214      7.417      1.133         24        480: 100% 5/5 [00:03<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.17it/s]\n",
            "                   all         19         38     0.0919     0.0263     0.0777     0.0263\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/99      6.42G      1.812      4.201      1.065         19        480: 100% 5/5 [00:02<00:00,  1.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.71it/s]\n",
            "                   all         19         38      0.489      0.447      0.508      0.223\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/99      6.46G      1.633       2.21          1         20        480: 100% 5/5 [00:03<00:00,  1.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.81it/s]\n",
            "                   all         19         38      0.887      0.947      0.975      0.582\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/99      6.46G      1.435      1.811      0.888         13        480: 100% 5/5 [00:03<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.01it/s]\n",
            "                   all         19         38      0.932      0.935      0.985      0.539\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/99      6.46G      1.437      1.643      0.927         19        480: 100% 5/5 [00:02<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.98it/s]\n",
            "                   all         19         38      0.972       0.45      0.777      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/99      6.46G       1.41      1.928       0.94         12        480: 100% 5/5 [00:02<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.96it/s]\n",
            "                   all         19         38      0.714      0.819      0.985      0.543\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/99      6.46G      1.586       1.18     0.9324         22        480: 100% 5/5 [00:03<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.54it/s]\n",
            "                   all         19         38      0.992      0.999      0.995       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/99      6.46G      1.457      1.125      0.913         23        480: 100% 5/5 [00:02<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.95it/s]\n",
            "                   all         19         38       0.98      0.998      0.995      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/99      6.46G      1.489      1.078     0.9132         12        480: 100% 5/5 [00:02<00:00,  1.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.07it/s]\n",
            "                   all         19         38      0.992      0.974       0.97      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/99      6.46G      1.793      1.018     0.9858         19        480: 100% 5/5 [00:03<00:00,  1.27it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.50it/s]\n",
            "                   all         19         38      0.992      0.974       0.97       0.51\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/99      6.46G      1.647      1.125     0.9581         15        480: 100% 5/5 [00:02<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.76it/s]\n",
            "                   all         19         38      0.945      0.998      0.995      0.533\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/99      6.46G      1.553      1.043     0.9403         14        480: 100% 5/5 [00:02<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.95it/s]\n",
            "                   all         19         38      0.837      0.917      0.993      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/99      6.46G      1.381       1.04     0.8973         14        480: 100% 5/5 [00:03<00:00,  1.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.13it/s]\n",
            "                   all         19         38      0.917      0.956      0.995      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/99      6.46G      1.537      1.238      0.937          6        480: 100% 5/5 [00:02<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.85it/s]\n",
            "                   all         19         38          1      0.995      0.995      0.596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/99      6.46G      1.796     0.9818     0.9363         21        480: 100% 5/5 [00:03<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.93it/s]\n",
            "                   all         19         38      0.995      0.974      0.993      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/99      6.46G      1.818     0.9186      1.005         16        480: 100% 5/5 [00:03<00:00,  1.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.60it/s]\n",
            "                   all         19         38      0.969      0.947      0.963      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/99      6.46G       1.82      1.186      1.005         29        480: 100% 5/5 [00:03<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.84it/s]\n",
            "                   all         19         38      0.992      0.963      0.994      0.494\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/99      6.46G      1.703      1.052     0.9546         22        480: 100% 5/5 [00:03<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.57it/s]\n",
            "                   all         19         38      0.973      0.974      0.993      0.553\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/99      6.46G      1.645      1.399     0.9481         16        480: 100% 5/5 [00:03<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.26it/s]\n",
            "                   all         19         38      0.959       0.96      0.994      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/99      6.46G       1.66      1.139     0.9287         18        480: 100% 5/5 [00:03<00:00,  1.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.54it/s]\n",
            "                   all         19         38      0.799      0.809      0.986      0.474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/5 [00:01<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov9/train.py\", line 634, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov9/train.py\", line 528, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/yolov9/train.py\", line 311, in train\n",
            "    scaler.scale(loss).backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 521, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 289, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}/yolov9\n",
        "\n",
        "!python train.py \\\n",
        "--batch 16 --epochs 100 --img 480 --device 0 --min-items 0 --close-mosaic 15 \\\n",
        "--data /content/yolov9/RAT_NOR-6/data.yaml \\\n",
        "--weights {HOME}/weights/gelan-c.pt \\\n",
        "--cfg /content/yolov9/models/detect/gelan-c.yaml \\\n",
        "--hyp hyp.scratch-high.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHsMq7wc3bve"
      },
      "source": [
        "**NOTE:** By default, the results of each subsequent training sessions are saved in `{HOME}/yolov9/runs/train/`, in directories named `exp`, `exp2`, `exp3`, ... You can override this behavior by using the `--name` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WslwgMAW2Euc",
        "outputId": "193fd1b2-429a-4efb-b94d-7661223c99c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exp  exp2\n"
          ]
        }
      ],
      "source": [
        "!ls {HOME}/yolov9/runs/train/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih1rk9O_4CYG"
      },
      "source": [
        "## Validate Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoZv8kNE4NxS",
        "outputId": "fac25d1a-65ae-4210-bc1b-187fe85cae69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov9\n",
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov9/RAT_NOR-6/data.yaml, weights=['/content/yolov9/runs/train/exp4/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False, min_items=0\n",
            "YOLOv5 ðŸš€ 1e33dbb Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "/content/yolov9/models/experimental.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov9/val.py\", line 389, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov9/val.py\", line 362, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov9/val.py\", line 122, in run\n",
            "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
            "  File \"/content/yolov9/models/common.py\", line 684, in __init__\n",
            "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
            "  File \"/content/yolov9/models/experimental.py\", line 75, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1065, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 468, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 449, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/yolov9/runs/train/exp4/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}/yolov9\n",
        "\n",
        "!python val.py \\\n",
        "--img 640 --batch 32 --conf 0.001 --iou 0.7 --device 0 \\\n",
        "--data {dataset.location}/data.yaml \\\n",
        "--weights {HOME}/yolov9/runs/train/exp4/weights/best.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJJ5fiqT6mEq"
      },
      "source": [
        "## Inference with Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vnrn9cwIsUs",
        "outputId": "fb814bfa-fb4f-4923-89ca-1f005af1c243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/best.pt'], source=/content/videos, data=data/coco128.yaml, imgsz=[480, 480], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ 1e33dbb Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "/content/yolov9/models/experimental.py:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 467 layers, 25412502 parameters, 0 gradients, 102.5 GFLOPs\n",
            "video 1/4 (1/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 65.6ms\n",
            "video 1/4 (2/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 24.4ms\n",
            "video 1/4 (3/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 24.3ms\n",
            "video 1/4 (4/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 24.3ms\n",
            "video 1/4 (5/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 24.2ms\n",
            "video 1/4 (6/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 28.8ms\n",
            "video 1/4 (7/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 25.8ms\n",
            "video 1/4 (8/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 26.1ms\n",
            "video 1/4 (9/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 26.5ms\n",
            "video 1/4 (10/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 18.5ms\n",
            "video 1/4 (11/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 26.1ms\n",
            "video 1/4 (12/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 24.8ms\n",
            "video 1/4 (13/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 22.8ms\n",
            "video 1/4 (14/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 21.4ms\n",
            "video 1/4 (15/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 19.6ms\n",
            "video 1/4 (16/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 26.0ms\n",
            "video 1/4 (17/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 24.8ms\n",
            "video 1/4 (18/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 21.9ms\n",
            "video 1/4 (19/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 26.2ms\n",
            "video 1/4 (20/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 22.1ms\n",
            "video 1/4 (21/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 23.6ms\n",
            "video 1/4 (22/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 19.8ms\n",
            "video 1/4 (23/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 22.4ms\n",
            "video 1/4 (24/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 21.5ms\n",
            "video 1/4 (25/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 21.1ms\n",
            "video 1/4 (26/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 21.5ms\n",
            "video 1/4 (27/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.8ms\n",
            "video 1/4 (28/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 25.6ms\n",
            "video 1/4 (29/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 26.4ms\n",
            "video 1/4 (30/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.7ms\n",
            "video 1/4 (31/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 22.4ms\n",
            "video 1/4 (32/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.6ms\n",
            "video 1/4 (33/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.5ms\n",
            "video 1/4 (34/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.5ms\n",
            "video 1/4 (35/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.7ms\n",
            "video 1/4 (36/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.6ms\n",
            "video 1/4 (37/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.8ms\n",
            "video 1/4 (38/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.6ms\n",
            "video 1/4 (39/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.2ms\n",
            "video 1/4 (40/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 22.9ms\n",
            "video 1/4 (41/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 19.4ms\n",
            "video 1/4 (42/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 19.8ms\n",
            "video 1/4 (43/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 24.5ms\n",
            "video 1/4 (44/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 29.7ms\n",
            "video 1/4 (45/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 23.8ms\n",
            "video 1/4 (46/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 25.9ms\n",
            "video 1/4 (47/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 21.3ms\n",
            "video 1/4 (48/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 35.8ms\n",
            "video 1/4 (49/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 27.5ms\n",
            "video 1/4 (50/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 26.2ms\n",
            "video 1/4 (51/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 22.7ms\n",
            "video 1/4 (52/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 21.2ms\n",
            "video 1/4 (53/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 25.3ms\n",
            "video 1/4 (54/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 25.5ms\n",
            "video 1/4 (55/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 26.8ms\n",
            "video 1/4 (56/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 27.3ms\n",
            "video 1/4 (57/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 24.6ms\n",
            "video 1/4 (58/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.8ms\n",
            "video 1/4 (59/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 26.0ms\n",
            "video 1/4 (60/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 29.5ms\n",
            "video 1/4 (61/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 28.2ms\n",
            "video 1/4 (62/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 25.6ms\n",
            "video 1/4 (63/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 24.1ms\n",
            "video 1/4 (64/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 23.8ms\n",
            "video 1/4 (65/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 25.6ms\n",
            "video 1/4 (66/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 24.2ms\n",
            "video 1/4 (67/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 25.5ms\n",
            "video 1/4 (68/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 22.7ms\n",
            "video 1/4 (69/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 24.6ms\n",
            "video 1/4 (70/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 28.6ms\n",
            "video 1/4 (71/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 24.8ms\n",
            "video 1/4 (72/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 23.2ms\n",
            "video 1/4 (73/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 23.5ms\n",
            "video 1/4 (74/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 25.9ms\n",
            "video 1/4 (75/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 31.9ms\n",
            "video 1/4 (76/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 32.8ms\n",
            "video 1/4 (77/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 23.9ms\n",
            "video 1/4 (78/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 27.7ms\n",
            "video 1/4 (79/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 28.9ms\n",
            "video 1/4 (80/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 26.2ms\n",
            "video 1/4 (81/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 29.1ms\n",
            "video 1/4 (82/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 28.1ms\n",
            "video 1/4 (83/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 35.1ms\n",
            "video 1/4 (84/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 22.5ms\n",
            "video 1/4 (85/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.1ms\n",
            "video 1/4 (86/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 18.3ms\n",
            "video 1/4 (87/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.2ms\n",
            "video 1/4 (88/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.9ms\n",
            "video 1/4 (89/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.9ms\n",
            "video 1/4 (90/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.5ms\n",
            "video 1/4 (91/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.3ms\n",
            "video 1/4 (92/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.3ms\n",
            "video 1/4 (93/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.2ms\n",
            "video 1/4 (94/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.0ms\n",
            "video 1/4 (95/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.2ms\n",
            "video 1/4 (96/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.7ms\n",
            "video 1/4 (97/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.0ms\n",
            "video 1/4 (98/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 17.4ms\n",
            "video 1/4 (99/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.9ms\n",
            "video 1/4 (100/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 26.2ms\n",
            "video 1/4 (101/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.0ms\n",
            "video 1/4 (102/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.4ms\n",
            "video 1/4 (103/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.1ms\n",
            "video 1/4 (104/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.0ms\n",
            "video 1/4 (105/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.7ms\n",
            "video 1/4 (106/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 19.1ms\n",
            "video 1/4 (107/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.5ms\n",
            "video 1/4 (108/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.9ms\n",
            "video 1/4 (109/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 26.8ms\n",
            "video 1/4 (110/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.2ms\n",
            "video 1/4 (111/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.6ms\n",
            "video 1/4 (112/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.4ms\n",
            "video 1/4 (113/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 19.5ms\n",
            "video 1/4 (114/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.5ms\n",
            "video 1/4 (115/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.2ms\n",
            "video 1/4 (116/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.0ms\n",
            "video 1/4 (117/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.0ms\n",
            "video 1/4 (118/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 17.8ms\n",
            "video 1/4 (119/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 18.1ms\n",
            "video 1/4 (120/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.7ms\n",
            "video 1/4 (121/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.7ms\n",
            "video 1/4 (122/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.8ms\n",
            "video 1/4 (123/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.8ms\n",
            "video 1/4 (124/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.1ms\n",
            "video 1/4 (125/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 19.0ms\n",
            "video 1/4 (126/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.9ms\n",
            "video 1/4 (127/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.8ms\n",
            "video 1/4 (128/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.4ms\n",
            "video 1/4 (129/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 17.3ms\n",
            "video 1/4 (130/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (131/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 17.0ms\n",
            "video 1/4 (132/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.6ms\n",
            "video 1/4 (133/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (134/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.2ms\n",
            "video 1/4 (135/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.2ms\n",
            "video 1/4 (136/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.7ms\n",
            "video 1/4 (137/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 18.0ms\n",
            "video 1/4 (138/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 17.1ms\n",
            "video 1/4 (139/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 23.4ms\n",
            "video 1/4 (140/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.3ms\n",
            "video 1/4 (141/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (142/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 18.3ms\n",
            "video 1/4 (143/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.3ms\n",
            "video 1/4 (144/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.9ms\n",
            "video 1/4 (145/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.1ms\n",
            "video 1/4 (146/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.3ms\n",
            "video 1/4 (147/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.7ms\n",
            "video 1/4 (148/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (149/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 23.8ms\n",
            "video 1/4 (150/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 19.0ms\n",
            "video 1/4 (151/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (152/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.0ms\n",
            "video 1/4 (153/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.8ms\n",
            "video 1/4 (154/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 19.3ms\n",
            "video 1/4 (155/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.0ms\n",
            "video 1/4 (156/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (157/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 18.1ms\n",
            "video 1/4 (158/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.8ms\n",
            "video 1/4 (159/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.2ms\n",
            "video 1/4 (160/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.2ms\n",
            "video 1/4 (161/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.7ms\n",
            "video 1/4 (162/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.8ms\n",
            "video 1/4 (163/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.6ms\n",
            "video 1/4 (164/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.4ms\n",
            "video 1/4 (165/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.2ms\n",
            "video 1/4 (166/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 18.7ms\n",
            "video 1/4 (167/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.9ms\n",
            "video 1/4 (168/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.0ms\n",
            "video 1/4 (169/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.4ms\n",
            "video 1/4 (170/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (171/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.2ms\n",
            "video 1/4 (172/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 18.1ms\n",
            "video 1/4 (173/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.9ms\n",
            "video 1/4 (174/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (175/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (176/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.3ms\n",
            "video 1/4 (177/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.5ms\n",
            "video 1/4 (178/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 17.1ms\n",
            "video 1/4 (179/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.5ms\n",
            "video 1/4 (180/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.1ms\n",
            "video 1/4 (181/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.1ms\n",
            "video 1/4 (182/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.0ms\n",
            "video 1/4 (183/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.8ms\n",
            "video 1/4 (184/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 25.8ms\n",
            "video 1/4 (185/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.2ms\n",
            "video 1/4 (186/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.7ms\n",
            "video 1/4 (187/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.1ms\n",
            "video 1/4 (188/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.2ms\n",
            "video 1/4 (189/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 26.9ms\n",
            "video 1/4 (190/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.1ms\n",
            "video 1/4 (191/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.7ms\n",
            "video 1/4 (192/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.1ms\n",
            "video 1/4 (193/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 17.3ms\n",
            "video 1/4 (194/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.4ms\n",
            "video 1/4 (195/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 22.5ms\n",
            "video 1/4 (196/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (197/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (198/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.2ms\n",
            "video 1/4 (199/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.9ms\n",
            "video 1/4 (200/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.1ms\n",
            "video 1/4 (201/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.9ms\n",
            "video 1/4 (202/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.1ms\n",
            "video 1/4 (203/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 23.1ms\n",
            "video 1/4 (204/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 27.2ms\n",
            "video 1/4 (205/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 24.1ms\n",
            "video 1/4 (206/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.4ms\n",
            "video 1/4 (207/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 16.8ms\n",
            "video 1/4 (208/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.9ms\n",
            "video 1/4 (209/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.5ms\n",
            "video 1/4 (210/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.9ms\n",
            "video 1/4 (211/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.4ms\n",
            "video 1/4 (212/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.1ms\n",
            "video 1/4 (213/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 21.2ms\n",
            "video 1/4 (214/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 22.6ms\n",
            "video 1/4 (215/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.5ms\n",
            "video 1/4 (216/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.9ms\n",
            "video 1/4 (217/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (218/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.6ms\n",
            "video 1/4 (219/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.0ms\n",
            "video 1/4 (220/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.2ms\n",
            "video 1/4 (221/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.8ms\n",
            "video 1/4 (222/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.7ms\n",
            "video 1/4 (223/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.4ms\n",
            "video 1/4 (224/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 18.7ms\n",
            "video 1/4 (225/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.9ms\n",
            "video 1/4 (226/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.8ms\n",
            "video 1/4 (227/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 23.9ms\n",
            "video 1/4 (228/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 14.9ms\n",
            "video 1/4 (229/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 17.4ms\n",
            "video 1/4 (230/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.2ms\n",
            "video 1/4 (231/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.0ms\n",
            "video 1/4 (232/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 18.4ms\n",
            "video 1/4 (233/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.6ms\n",
            "video 1/4 (234/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.9ms\n",
            "video 1/4 (235/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.2ms\n",
            "video 1/4 (236/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 17.1ms\n",
            "video 1/4 (237/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.6ms\n",
            "video 1/4 (238/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (239/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.5ms\n",
            "video 1/4 (240/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.8ms\n",
            "video 1/4 (241/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.1ms\n",
            "video 1/4 (242/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.4ms\n",
            "video 1/4 (243/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.5ms\n",
            "video 1/4 (244/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.8ms\n",
            "video 1/4 (245/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.1ms\n",
            "video 1/4 (246/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.9ms\n",
            "video 1/4 (247/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.3ms\n",
            "video 1/4 (248/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 19.4ms\n",
            "video 1/4 (249/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.0ms\n",
            "video 1/4 (250/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.6ms\n",
            "video 1/4 (251/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.0ms\n",
            "video 1/4 (252/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 17.6ms\n",
            "video 1/4 (253/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 23.6ms\n",
            "video 1/4 (254/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.9ms\n",
            "video 1/4 (255/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.3ms\n",
            "video 1/4 (256/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.4ms\n",
            "video 1/4 (257/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.6ms\n",
            "video 1/4 (258/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.1ms\n",
            "video 1/4 (259/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.8ms\n",
            "video 1/4 (260/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.6ms\n",
            "video 1/4 (261/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.2ms\n",
            "video 1/4 (262/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.6ms\n",
            "video 1/4 (263/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.4ms\n",
            "video 1/4 (264/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.6ms\n",
            "video 1/4 (265/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 20.2ms\n",
            "video 1/4 (266/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 16.3ms\n",
            "video 1/4 (267/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 24.8ms\n",
            "video 1/4 (268/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 16.0ms\n",
            "video 1/4 (269/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.0ms\n",
            "video 1/4 (270/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 14.6ms\n",
            "video 1/4 (271/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 14.8ms\n",
            "video 1/4 (272/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 17.8ms\n",
            "video 1/4 (273/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.8ms\n",
            "video 1/4 (274/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.4ms\n",
            "video 1/4 (275/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 16.1ms\n",
            "video 1/4 (276/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 16.9ms\n",
            "video 1/4 (277/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.9ms\n",
            "video 1/4 (278/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.3ms\n",
            "video 1/4 (279/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.8ms\n",
            "video 1/4 (280/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 14.9ms\n",
            "video 1/4 (281/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 16.3ms\n",
            "video 1/4 (282/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.8ms\n",
            "video 1/4 (283/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.5ms\n",
            "video 1/4 (284/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 20.5ms\n",
            "video 1/4 (285/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 16.6ms\n",
            "video 1/4 (286/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 16.3ms\n",
            "video 1/4 (287/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.3ms\n",
            "video 1/4 (288/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.8ms\n",
            "video 1/4 (289/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.5ms\n",
            "video 1/4 (290/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 14.9ms\n",
            "video 1/4 (291/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.3ms\n",
            "video 1/4 (292/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 16.4ms\n",
            "video 1/4 (293/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 18.1ms\n",
            "video 1/4 (294/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.9ms\n",
            "video 1/4 (295/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.8ms\n",
            "video 1/4 (296/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 20.8ms\n",
            "video 1/4 (297/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.1ms\n",
            "video 1/4 (298/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.7ms\n",
            "video 1/4 (299/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 14.9ms\n",
            "video 1/4 (300/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 17.3ms\n",
            "video 1/4 (301/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 17.7ms\n",
            "video 1/4 (302/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.2ms\n",
            "video 1/4 (303/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 16.2ms\n",
            "video 1/4 (304/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 21.4ms\n",
            "video 1/4 (305/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 16.0ms\n",
            "video 1/4 (306/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 17.4ms\n",
            "video 1/4 (307/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.2ms\n",
            "video 1/4 (308/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 19.4ms\n",
            "video 1/4 (309/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 23.2ms\n",
            "video 1/4 (310/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.6ms\n",
            "video 1/4 (311/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.3ms\n",
            "video 1/4 (312/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 17.7ms\n",
            "video 1/4 (313/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 TL_Object, 15.2ms\n",
            "video 1/4 (314/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.6ms\n",
            "video 1/4 (315/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.0ms\n",
            "video 1/4 (316/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.9ms\n",
            "video 1/4 (317/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 18.8ms\n",
            "video 1/4 (318/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.7ms\n",
            "video 1/4 (319/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.7ms\n",
            "video 1/4 (320/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.6ms\n",
            "video 1/4 (321/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.1ms\n",
            "video 1/4 (322/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.3ms\n",
            "video 1/4 (323/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.6ms\n",
            "video 1/4 (324/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.1ms\n",
            "video 1/4 (325/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 18.1ms\n",
            "video 1/4 (326/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.9ms\n",
            "video 1/4 (327/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.8ms\n",
            "video 1/4 (328/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 20.4ms\n",
            "video 1/4 (329/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.2ms\n",
            "video 1/4 (330/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.7ms\n",
            "video 1/4 (331/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.5ms\n",
            "video 1/4 (332/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 19.5ms\n",
            "video 1/4 (333/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.8ms\n",
            "video 1/4 (334/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 14.9ms\n",
            "video 1/4 (335/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.9ms\n",
            "video 1/4 (336/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.8ms\n",
            "video 1/4 (337/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 16.0ms\n",
            "video 1/4 (338/15913) /content/videos/NOR10_Acq_R6.mp4: 288x480 1 BR_Object, 1 TL_Object, 15.8ms\n"
          ]
        }
      ],
      "source": [
        "!python detect.py \\\n",
        "--img 480 --conf 0.5 --device 0 \\\n",
        "--weights /content/best.pt \\\n",
        "--source \"/content/videos\" \\\n",
        "--save-txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import re\n",
        "\n",
        "# Define screen dimensions\n",
        "SCREEN_WIDTH = 852\n",
        "SCREEN_HEIGHT = 480\n",
        "\n",
        "# Function to convert relative coordinates to pixels\n",
        "def to_pixel_coords(relative_x, relative_y):\n",
        "    pixel_x = round(relative_x * SCREEN_WIDTH)\n",
        "    pixel_y = round(relative_y * SCREEN_HEIGHT)\n",
        "    return pixel_x, pixel_y\n",
        "\n",
        "# Directory containing the text files\n",
        "labels_dir = \"/content/yolov9/runs/detect/exp5/labels\"\n",
        "\n",
        "# Directory where the CSV files will be saved\n",
        "output_dir = \"/content/csv/\"\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# Loop over the range of sets (1 to 18)\n",
        "for i in range(1, 19):\n",
        "    # Create the output CSV file for this set\n",
        "    output_file = os.path.join(output_dir, f\"video_frames_R{i}.csv\")\n",
        "\n",
        "    # Create a list to store (frame_number, file_path) tuples\n",
        "    frame_files = []\n",
        "\n",
        "    # Process each text file\n",
        "    for filename in os.listdir(labels_dir):\n",
        "        if filename.startswith(f\"NOR10_Acq_R{i}\") and filename.endswith(\".txt\"):\n",
        "            # Extract frame number from the end of the filename (digits before .txt)\n",
        "            match = re.search(r'_(\\d+)\\.txt$', filename)\n",
        "            if match:\n",
        "                frame_number = int(match.group(1))  # Extract the frame number as an integer\n",
        "                file_path = os.path.join(labels_dir, filename)\n",
        "                frame_files.append((frame_number, file_path))\n",
        "\n",
        "    # Sort the frame files by frame number\n",
        "    frame_files.sort(key=lambda x: x[0])\n",
        "\n",
        "    # Write header to the CSV file\n",
        "    with open(output_file, mode='w', newline='') as csvfile:\n",
        "        csvwriter = csv.writer(csvfile)\n",
        "        csvwriter.writerow([\"frame_number\", \"br_x\", \"br_y\", \"tl_x\", \"tl_y\"])\n",
        "\n",
        "        # Process sorted files\n",
        "        for frame_number, file_path in frame_files:\n",
        "            # Read the coordinates from the file\n",
        "            with open(file_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "                # Make sure there are enough lines to avoid index errors\n",
        "                if len(lines) >= 2:\n",
        "                    br_data = lines[0].split()\n",
        "                    tl_data = lines[1].split()\n",
        "\n",
        "                    # Extract relative coordinates\n",
        "                    br_relative_x = float(br_data[1])\n",
        "                    br_relative_y = float(br_data[2])\n",
        "                    tl_relative_x = float(tl_data[1])\n",
        "                    tl_relative_y = float(tl_data[2])\n",
        "\n",
        "                    # Convert coordinates to pixels\n",
        "                    br_x, br_y = to_pixel_coords(br_relative_x, br_relative_y)\n",
        "                    tl_x, tl_y = to_pixel_coords(tl_relative_x, tl_relative_y)\n",
        "\n",
        "                    # Write to CSV\n",
        "                    csvwriter.writerow([frame_number, br_x, br_y, tl_x, tl_y])\n",
        "\n",
        "    print(f\"CSV file created: {output_file}\")\n"
      ],
      "metadata": {
        "id": "lcizEmW1neHJ",
        "outputId": "2a233e94-09af-4cc3-f2c8-c16269558b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file created: /content/csv/video_frames_R1.csv\n",
            "CSV file created: /content/csv/video_frames_R2.csv\n",
            "CSV file created: /content/csv/video_frames_R3.csv\n",
            "CSV file created: /content/csv/video_frames_R4.csv\n",
            "CSV file created: /content/csv/video_frames_R5.csv\n",
            "CSV file created: /content/csv/video_frames_R6.csv\n",
            "CSV file created: /content/csv/video_frames_R7.csv\n",
            "CSV file created: /content/csv/video_frames_R8.csv\n",
            "CSV file created: /content/csv/video_frames_R9.csv\n",
            "CSV file created: /content/csv/video_frames_R10.csv\n",
            "CSV file created: /content/csv/video_frames_R11.csv\n",
            "CSV file created: /content/csv/video_frames_R12.csv\n",
            "CSV file created: /content/csv/video_frames_R13.csv\n",
            "CSV file created: /content/csv/video_frames_R14.csv\n",
            "CSV file created: /content/csv/video_frames_R15.csv\n",
            "CSV file created: /content/csv/video_frames_R16.csv\n",
            "CSV file created: /content/csv/video_frames_R17.csv\n",
            "CSV file created: /content/csv/video_frames_R18.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IDM3QPKdQZk",
        "outputId": "9c08df29-2b97-4673-8b01-2b8493129116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "open(/content/yolov9/runs/detect/exp/labelsNOR10_Acq_R2_5272.txt)"
      ],
      "metadata": {
        "id": "X5nXCx43k8LM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "24b08d6c-7fd8-4639-c1d3-1c1cf3de51d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-22-e84a6eb6a5b1>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-e84a6eb6a5b1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    open(/content/yolov9/runs/detect/exp/labelsNOR10_Acq_R2_5272.txt)\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j8y8eG0zo409"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}